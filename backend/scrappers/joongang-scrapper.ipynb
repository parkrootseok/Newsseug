{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\SSAFY\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\SSAFY\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "   ---------------------------------------- 0.0/147.9 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 30.7/147.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 147.9/147.9 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\SSAFY\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "%pip install pandas\n",
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéà ÌÖåÏä§Ìä∏\n",
    "\n",
    "### **ÏÉÅÎã® 10Í±¥ÏùÑ Ï°∞ÌöåÌïòÏó¨ Ìïú ÌååÏùºÏóê Ï†ÄÏû•**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping article: https://www.joongang.co.kr/article/25278499\n",
      "Skipping article https://www.joongang.co.kr/article/25278499: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278695\n",
      "Skipping article https://www.joongang.co.kr/article/25278695: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278704\n",
      "Skipping article https://www.joongang.co.kr/article/25278704: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278716\n",
      "Skipping article https://www.joongang.co.kr/article/25278716: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278507\n",
      "Skipping article https://www.joongang.co.kr/article/25278507: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278704\n",
      "Skipping article https://www.joongang.co.kr/article/25278704: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278705\n",
      "Scraping article: https://www.joongang.co.kr/article/25278773\n",
      "Scraping article: https://www.joongang.co.kr/article/25278775\n",
      "Scraping article: https://www.joongang.co.kr/article/25278590\n",
      "Scraping article: https://www.joongang.co.kr/article/25278775\n",
      "Scraping article: https://www.joongang.co.kr/article/25278773\n",
      "Scraping article: https://www.joongang.co.kr/article/25278717\n",
      "Scraping article: https://www.joongang.co.kr/article/25278705\n",
      "Scraping article: https://www.joongang.co.kr/article/25278708\n",
      "Scraping article: https://www.joongang.co.kr/article/25278704\n",
      "Skipping article https://www.joongang.co.kr/article/25278704: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278702\n",
      "Scraping article: https://www.joongang.co.kr/article/25278701\n",
      "Scraping article: https://www.joongang.co.kr/article/25278677\n",
      "Scraping article: https://www.joongang.co.kr/article/25278673\n",
      "Scraping article: https://www.joongang.co.kr/article/25278671\n",
      "Scraping article: https://www.joongang.co.kr/article/25278638\n",
      "Scraping article: https://www.joongang.co.kr/article/25278630\n",
      "Scraping article: https://www.joongang.co.kr/article/25278620\n",
      "Scraping article: https://www.joongang.co.kr/article/25278610\n",
      "Scraping article: https://www.joongang.co.kr/article/25278607\n",
      "Scraping article: https://www.joongang.co.kr/article/25278598\n",
      "Scraping article: https://www.joongang.co.kr/article/25278590\n",
      "Scraping article: https://www.joongang.co.kr/article/25278576\n",
      "Skipping article https://www.joongang.co.kr/article/25278576: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278562\n",
      "Scraping article: https://www.joongang.co.kr/article/25278556\n",
      "Scraping article: https://www.joongang.co.kr/article/25278536\n",
      "Scraping article: https://www.joongang.co.kr/article/25278532\n",
      "Scraping article: https://www.joongang.co.kr/article/25278529\n",
      "                                         headline                      time  \\\n",
      "0        '7Í∞ú ÏÇ¨Í±¥' Ïû¨Ìåê Ï§ëÏù∏ Ïù¥Ïû¨Î™Ö, Ïò§Îäò Í≥µÏßÅÏÑ†Í±∞Î≤ï ÌòêÏùò Í≤∞Ïã¨‚Ä¶Í∏∞ÏÜå 2ÎÖÑÎßå  2024-09-20T06:19:14+0900   \n",
      "1             Â∞π \"Ï≤¥ÏΩîÏôÄ ÏõêÏûêÎ†• ÎèôÎßπ Íµ¨Ï∂ï\" ÌååÎ≤® \"ÌïúÏàòÏõê ÏµúÏ¢Ö ÏàòÏ£º ÎÇôÍ¥Ä\"  2024-09-20T05:55:43+0900   \n",
      "2             Êñá 'ÌÜµÏùºÎã¥Î°† Ïû¨Í≤ÄÌÜ†'Ïóê‚Ä¶Ïö©ÏÇ∞ \"ÎßêÎ°úÎßå ÌèâÌôîÏôîÎã§Í≥† ÏÑ∏Í≥ÑÏóê Î°úÎπÑ\"  2024-09-20T05:18:48+0900   \n",
      "3               \"Ïù¥Ïû¨Î™ÖÏù¥ÎÉê Ï°∞Íµ≠Ïù¥ÎÉê ÏïÑÎãàÍ≤ÑÏÜå\" Íµ∞Ïàò Ïû¨ÏÑ†Í±∞Ïóê Ìò∏ÎÇ® Îì§Ïç©Ïù∏Îã§  2024-09-20T05:00:04+0900   \n",
      "4   Í∞ÄÏû• Ï∑®ÏïΩÌïú ÎÇ† ÎÖ∏Î†∏Îã§‚Ä¶ÎèÖÎ¶ΩÍ∏∞ÎÖêÏùºÏóê ÁæéÎÑ§Ìä∏ÏõåÌÅ¨ ÎÇúÌÉÄÌïú Í∑∏Îì§ [Focus Ïù∏ÏÇ¨Ïù¥Îìú]  2024-09-20T05:00:01+0900   \n",
      "5             Ìïú-Ï≤¥ÏΩî Ï†ïÏÉÅ, Ïõ®Ïä§ÌåÖÌïòÏö∞Ïä§ Î∂ÑÏüÅÏóê \"Ïûò Ìï¥Í≤∞Îê† Í≤É\" Ìïú Î™©ÏÜåÎ¶¨  2024-09-20T04:17:41+0900   \n",
      "6              Ï≤¥ÏΩî Ï∞æÏùÄ Â∞π 'ÏõêÏ†ÑÎèôÎßπ' Ï¥ùÎ†•‚Ä¶ÁæéÍ∏∞ÏóÖÍ≥º Î∂ÑÏüÅÏóî \"Í±±Ï†ï ÎßêÎùº\"  2024-09-20T03:28:58+0900   \n",
      "7         [view] Í±∞Ïïº Î≤ïÏïà Í∞ïÌñâ, Ïö©ÏÇ∞ Í±∞Î∂ÄÍ∂å‚Ä¶‚ÄòÎπÑÌÜ†ÌÅ¨ÎùºÏãú‚Äô Î∞òÎ≥µÌïòÎäî Ï†ïÏπò  2024-09-20T00:34:22+0900   \n",
      "8                ÎåÄÌÜµÎ†π Î∞∞ÏõÖ ÌïúÎèôÌõà, 24ÏùºÏóî Ïö©ÏÇ∞ÎßåÏ∞¨‚Ä¶Ïú§¬∑Ìïú ÌÑ∞ÎãùÌè¨Ïù∏Ìä∏?  2024-09-20T00:20:11+0900   \n",
      "9           ÍπÄÏ†ïÏùÄ 'Ï†ÅÎåÄÏ†Å Îëê Íµ≠Í∞ÄÎ°†' Ïô∏Ïπú Îí§‚Ä¶ÏûÑÏ¢ÖÏÑù \"ÌÜµÏùº, ÌïòÏßÄ ÎßôÏãúÎã§\"  2024-09-20T00:18:16+0900   \n",
      "10      ÌïúÍµ≠Ïù∏ ‚ÄúÏùºÎ≥∏Ïóê Ìò∏Í∞ê‚Äù ÎäòÏóàÏßÄÎßå, ÏÇ¨ÎèÑÍ¥ëÏÇ∞ Ï†ïÎ∂Ä ÎåÄÏùëÏóî 60%Í∞Ä ‚ÄúÎ™ªÌñàÎã§‚Äù  2024-09-20T00:01:00+0900   \n",
      "11                'ÏùòÎ£å ÌòëÏùòÏ≤¥' ÏÇ¨Ìôú Í±¥ ÌïúÎèôÌõà, ÏùòÌòëÌöåÏû•Í≥º ÎπÑÍ≥µÍ∞ú ÌöåÎèô  2024-09-19T23:26:33+0900   \n",
      "12           Êñá \"ÎÇ®Î∂Å Í∏∞Ï°¥ ÌèâÌôî Îã¥Î°† Ïû¨Í≤ÄÌÜ†Ìï¥Ïïº‚Äù‚Ä¶ÏûÑÏ¢ÖÏÑù \"ÌÜµÏùº ÎåÄÏã† ÌèâÌôî\"  2024-09-19T20:41:06+0900   \n",
      "13            ÌÜµÏùº Ïô∏ÏπòÎçò ÏûÑÏ¢ÖÏÑù \"ÌÜµÏùº ÎßêÏûê\"‚Ä¶Ëàá \"ÍπÄÏ†ïÏùÄÏóê Î∞úÎßûÏ∂òÎã§\" ÎπÑÎÇú  2024-09-19T18:54:04+0900   \n",
      "14      [View] Èáé, Ïó∞Ìú¥ ÎÅùÎÇòÏûê Ï†ïÏüÅ 3Î≤ï Îòê Í∞ïÌñâ Ï≤òÎ¶¨‚Ä¶ÎπÑÌÜ†ÌÅ¨ÎùºÏãúÏùò ÏïÖÏàúÌôò  2024-09-19T18:32:57+0900   \n",
      "15          Â∞π Î∞∞ÏõÖ ÎÇòÏÑ† ÌïúÎèôÌõà, 24ÏùºÏóî ÎåÄÌÜµÎ†πÏã§ ÎßåÏ∞¨‚Ä¶Ïùò¬∑Ï†ïÍ∞àÎì± Ìï¥Î≤ï Ï∞æÎÇò  2024-09-19T17:43:52+0900   \n",
      "16             Íµ≥Í≤å Ïû†Í∏¥ Ï∂ïÍµ¨ÌòëÌöå Í±¥Î¨º‚Ä¶ÏßÑÏ¢ÖÏò§ \"Ï°∞ÏßÅÏ†Å ÏùÄÌèê ÏãúÏûëÎêêÎã§\" Í≤ΩÍ≥†  2024-09-19T17:00:28+0900   \n",
      "17      Ïù¥Ïû¨Î™Ö ‚ÄúÏ£ºÏãù ÌåîÏïÑÏïº ÌïòÎÉêÍ≥† Î¨ªÎäî ÎÖ∏Ïù∏Îì§ÏóêÍ≤å ‚ÄòÏïà ÏÇ¨Îäî Í≤å Ï¢ãÎã§‚ÄôÍ≥† ÎãµÌï¥‚Äù  2024-09-19T16:10:13+0900   \n",
      "18            \"ÌïúÎèôÌõà Í≥®Îì†ÌÉÄÏûÑÏùÄ 10Ïõî\"‚Ä¶Ïó¨Í∂å ÏßÄÏßÄÏú® ÌïòÎùΩÏÑ∏, Ïó∞ÎßêÍπåÏßÄ Í∞ÄÎÇò  2024-09-19T16:00:58+0900   \n",
      "19          TVÏàòÏã†Î£å Î∂ÑÎ¶¨ÏßïÏàò ÌõÑ ÏßïÏàòÏï° 65Ïñµ Í∞êÏÜå‚Ä¶KBS Ï≤´ Î¨¥Í∏âÌú¥ÏßÅ Ï∂îÏßÑ  2024-09-19T15:21:02+0900   \n",
      "20          ÎåÄÌÜµÎ†πÏã§ \"ÏùòÎ£åÍ≥Ñ, ÎåÄÌôîÏùò Ïû• ÎÇòÏôÄÎùº‚Ä¶ 2026ÎÖÑ Ï†ïÏõê Ï°∞Ï†ï Í∞ÄÎä•\"  2024-09-19T15:11:33+0900   \n",
      "21              Ìï¥Íµ∞ ÂâçÎåÄÎ†π, ÌòÑÏó≠ ÏãúÏ†à Î∂ÄÌïò ÏßÑÍ∏â ÎØ∏ÎÅºÎ°ú Í≥®ÌîÑÏ±Ñ¬∑Î™ÖÌíà ÏàòÏàò  2024-09-19T15:08:26+0900   \n",
      "\n",
      "                                              content reporter  \n",
      "0   Ïù¥Ïû¨Î™Ö ÎçîÎ∂àÏñ¥ÎØºÏ£ºÎãπ ÎåÄÌëúÍ∞Ä ÏßÄÎÇú 6Ïùº ÏÑúÏö∏ ÏÑúÏ¥àÍµ¨ Ï§ëÏïôÏßÄÎ∞©Î≤ïÏõêÏóêÏÑú Ïó¥Î¶∞ Í≥µÏßÅÏÑ†Í±∞Î≤ï ...      Ï†ïÌòúÏ†ï  \n",
      "1   ÌéòÌä∏Î•¥ ÌååÎ≤® Ï≤¥ÏΩî ÎåÄÌÜµÎ†πÏù¥ 19Ïùº(ÌòÑÏßÄÏãúÍ∞Ñ) ÌïúÍµ≠ÏàòÎ†•ÏõêÏûêÎ†•(ÌïúÏàòÏõê)Ïùò Ï≤¥ÏΩî ÎëêÏΩîÎ∞îÎãà...       ÌóàÏßÑ  \n",
      "2   19Ïùº Ïò§ÌõÑ Í¥ëÏ£º ÏÑúÍµ¨ ÍπÄÎåÄÏ§ëÏª®Î≤§ÏÖòÏÑºÌÑ∞ Îã§Î™©Ï†ÅÌôÄÏóêÏÑú Ïó¥Î¶∞ '9¬∑19 ÌèâÏñëÍ≥µÎèôÏÑ†Ïñ∏ 6...       ÌóàÏßÑ  \n",
      "3   Ï†ÑÎÇ® ÏòÅÍ¥ë ÌÑ∞ÎØ∏ÎÑê ÏãúÏû•ÏóêÏÑú Íµ¥ÎπÑ Í∞ÄÍ≤åÎ•º Ïö¥ÏòÅÌïòÎäî Ï°∞ÏòÅÏàú(71)Ïî®. ÍπÄÏ†ïÏû¨ Í∏∞Ïûê‚ÄúÏù¥Î≤à...      ÍπÄÌö®ÏÑ±  \n",
      "4   2009ÎÖÑ 7Ïõî 7Ïùº ÏùºÏù¥ÏóàÎã§. ÎåÄÌïúÎØºÍµ≠Í≥º ÎØ∏Íµ≠Ïùò Ï£ºÏöî Ï†ïÎ∂ÄÍ∏∞Í¥Ä, Ìè¨ÌÑ∏ ÏÇ¨Ïù¥Ìä∏, ÏùÄ...      Î∞ïÎèôÌúò  \n",
      "5   Ïú§ÏÑùÏó¥ ÎåÄÌÜµÎ†πÍ≥º ÌéòÌä∏Î•¥ ÌååÎ≤® Ï≤¥ÏΩî ÎåÄÌÜµÎ†πÏù¥ 19Ïùº(ÌòÑÏßÄÏãúÍ∞Ñ) Ï≤¥ÏΩî ÌîÑÎùºÌïòÏÑ±ÏóêÏÑú Ìïú¬∑...       ÌóàÏßÑ  \n",
      "6   Ïú§ÏÑùÏó¥ ÎåÄÌÜµÎ†πÍ≥º ÍπÄÍ±¥Ìù¨ Ïó¨ÏÇ¨Í∞Ä 19Ïùº ÏÑ±ÎÇ® ÏÑúÏö∏Í≥µÌï≠ÏóêÏÑú Ï≤¥ÏΩî Í≥µÏãù Î∞©Î¨∏ÏùÑ ÏúÑÌï¥ Ï∂úÍµ≠...      Î∞ïÌÉúÏù∏  \n",
      "7   19Ïùº Ïò§ÌõÑ Íµ≠Ìöå Î≥∏ÌöåÏùòÏóêÏÑú ÏïºÎãπÏùò ÏûÖÎ≤ï Í∞ïÌñâÏóê Î∞òÎ∞úÌïú Íµ≠ÎØºÏùòÌûò ÏùòÏõêÎì§Ïù¥ Î∂àÏ∞∏Ìïú Í∞Ä...      Ïù¥Ï∞ΩÌõà  \n",
      "8   Ï≤¥ÏΩîÎ•º Í≥µÏãù Î∞©Î¨∏Ìïú Ïú§ÏÑùÏó¥ ÎåÄÌÜµÎ†πÍ≥º ÍπÄÍ±¥Ìù¨ Ïó¨ÏÇ¨Í∞Ä 19Ïùº(ÌòÑÏßÄÏãúÍ∞Å) ÌîÑÎùºÌïò Î∞îÏ∏®ÎùºÌîÑ...      ÍπÄÎØºÏ†ï  \n",
      "9   Î¨∏Ïû¨Ïù∏ Ï†ïÎ∂ÄÏùò Ï¥àÎåÄ ÎåÄÌÜµÎ†πÎπÑÏÑúÏã§Ïû•ÏùÑ ÏßÄÎÇ∏ ÏûÑÏ¢ÖÏÑù(ÏÇ¨ÏßÑ) Ï†Ñ Ïã§Ïû•Ïù¥ 19Ïùº ÌÜµÏùºÏùÑ Ìïò...      Í∞ïÎ≥¥ÌòÑ  \n",
      "10  ÌïúÍµ≠Ïù∏ Ïó¥ Î™Ö Ï§ë ÎÑ§ Î™ÖÏùÄ ÏùºÎ≥∏Ïóê ÎåÄÌï¥ Ï¢ãÏùÄ Ïù∏ÏÉÅÏùÑ Í∞ñÍ≥† ÏûàÎã§Îäî Ïó¨Î°†Ï°∞ÏÇ¨ Í≤∞Í≥ºÍ∞Ä ÎÇò...      Î∞ïÌòÑÏ£º  \n",
      "11  ÌïúÎèôÌõà Íµ≠ÎØºÏùòÌûò ÎåÄÌëúÎäî 19Ïùº ÏµúÍ≥†ÏúÑÏóêÏÑú \"ÏßÄÍ∏à Ïó¨ÏïºÏùòÏ†ï ÌòëÏùòÏ≤¥Í∞Ä ÏïÑÎãàÎ©¥ Ïù¥ Î¨∏Ï†úÎ•º...      ÍπÄÏ≤†ÏõÖ  \n",
      "12  19Ïùº Ïò§ÌõÑ Í¥ëÏ£º ÏÑúÍµ¨ ÍπÄÎåÄÏ§ëÏª®Î≤§ÏÖòÏÑºÌÑ∞ Îã§Î™©Ï†ÅÌôÄÏóêÏÑú Ïó¥Î¶∞ '9¬∑19 ÌèâÏñëÍ≥µÎèôÏÑ†Ïñ∏ 6...      Í∞ïÎ≥¥ÌòÑ  \n",
      "13  ÏûÑÏ¢ÖÏÑù 2018 ÎÇ®Î∂ÅÏ†ïÏÉÅÌöåÎã¥ Ï§ÄÎπÑÏúÑÏõêÏû•Ïù¥ 19Ïùº Í¥ëÏ£º ÍπÄÎåÄÏ§ëÏª®Î≤§ÏÖòÏÑºÌÑ∞ÏóêÏÑú Ïó¥Î¶∞ 9¬∑...      Ïù¥Ìï¥Ï§Ä  \n",
      "14  Ï∂îÏÑù Ïó∞Ìú¥Í∞Ä ÎÅùÎÇòÏûêÎßàÏûê Íµ≠ÌöåÏóêÏÑ† Í±∞ÎåÄ ÏïºÎãπÏùò Î≤ïÏïà Í∞ïÌñâ Ï≤òÎ¶¨ÏôÄ ÏÜåÏàò Ïó¨ÎãπÏùò Î∞òÎ∞ú, ...      Í∞ïÎ≥¥ÌòÑ  \n",
      "15  Ïú§ÏÑùÏó¥ ÎåÄÌÜµÎ†πÏù¥ 19Ïùº ÏÑ±ÎÇ® ÏÑúÏö∏Í≥µÌï≠ÏóêÏÑú Ï≤¥ÏΩî ÏàúÎ∞©ÏùÑ ÏúÑÌï¥ Ï∂úÍµ≠ÌïòÎ©∞ ÌôòÏÜ° ÎÇòÏò® ÌïúÎèô...      ÍπÄÎØºÏ†ï  \n",
      "16  ÏßÑÏ¢ÖÏò§ Íµ≠ÎØºÏùòÌûò ÏùòÏõêÏù¥ 9Ïùº Ïò§Ï†Ñ ÏÑúÏö∏ Ïó¨ÏùòÎèÑ Íµ≠Ìöå ÏÜåÌÜµÍ¥ÄÏóêÏÑú Ï≤¥Ïú°Í≥Ñ ÎπÑÎ¶¨ Íµ≠ÎØº Ï†ú...      Î∞∞Ïû¨ÏÑ±  \n",
      "17  Ïù¥Ïû¨Î™Ö ÎçîÎ∂àÏñ¥ÎØºÏ£ºÎãπ ÎåÄÌëúÍ∞Ä 19Ïùº Ïò§ÌõÑ ÏÑúÏö∏ Ïó¨ÏùòÎèÑ Íµ≠ÌöåÏóêÏÑú Ïó¥Î¶∞ ÏùòÏõêÏ¥ùÌöåÏóêÏÑú Î™®Îëê...      Î∞∞Ïû¨ÏÑ±  \n",
      "18  Ïú§ÏÑùÏó¥ ÎåÄÌÜµÎ†πÍ≥º Íµ≠ÎØºÏùòÌûò ÏßÄÏßÄÏú®Ïù¥ ÏµúÍ∑º ÎèôÎ∞òÌïòÎùΩÌïòÎ©¥ÏÑú Ïó¨Í∂å Ï†ÑÏ≤¥Ïóê ÏúÑÍ∏∞Í∞êÏù¥ ÌåΩÎ∞∞ÌïòÎã§...      ÏÜêÍµ≠Ìù¨  \n",
      "19  ÏßÄÎÇú 7Ïõî 11Ïùº ÏÑúÏö∏ Ï¢ÖÎ°úÍµ¨ Í¥ëÌôîÎ¨∏Ïö∞Ï≤¥Íµ≠Ïóê KBS TV Î∞©ÏÜ° ÏàòÏã†Î£å Í≥†ÏßÄÏÑúÍ∞Ä ÎÜìÏó¨...      Î∞∞Ïû¨ÏÑ±  \n",
      "20  Ïû•ÏÉÅÏú§ ÏÇ¨ÌöåÏàòÏÑùÏù¥ 19Ïùº ÏÑúÏö∏ Ïö©ÏÇ∞ ÎåÄÌÜµÎ†πÏã§ Ï≤≠ÏÇ¨ Î∏åÎ¶¨ÌïëÎ£∏ÏóêÏÑú Ï∂îÏÑù Ïó∞Ìú¥ ÏùëÍ∏âÏùòÎ£å ...      Ïù¥Ìï¥Ï§Ä  \n",
      "21  Í≥®ÌîÑ ÏûêÎ£åÏÇ¨ÏßÑ. ÏÇ¨ÏßÑ ÌîΩÏÇ¨Î≤†Ïù¥Ìï¥Íµ∞ Ï†Ñ ÎåÄÎ†πÏù¥ ÌòÑÏó≠ ÏãúÏ†à ÏûêÏã†Ïùò ÏßÅÎ¨¥ÏÉÅ Í∂åÌïúÏùÑ ÏàòÏãúÎ°ú...      ÌïúÏòÅÌòú  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "joongang_news_df = pd.DataFrame(columns=['headline', 'time', 'content', 'reporter'])\n",
    "idx = 0\n",
    "header = {'User-Agent' : ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "                          '(KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'),}\n",
    "\n",
    "# Ïä§ÌÅ¨Îû© Ìï®Ïàò\n",
    "def scrape_article(article_url):\n",
    "    response = requests.get(article_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        category = soup.find('a', { 'class': 'title' }).get_text(strip=True)\n",
    "        if category != 'Ï†ïÏπò': # Ï†ïÏπòÍ∞Ä ÏïÑÎãàÎ©¥ Skip\n",
    "            print(f\"Skipping article {article_url}: not a Politics article.\")\n",
    "            return None\n",
    "    except AttributeError:\n",
    "        print(f\"Skipping article {article_url}: category not found.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        headline = soup.find('h1', { 'class': 'headline' }).get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        headline = 'N/A'\n",
    "\n",
    "    try:\n",
    "        date = soup.find('p', { 'class': 'date' })\n",
    "        time = date.find('time').get('datetime')\n",
    "    except AttributeError:\n",
    "        time = 'N/A'\n",
    "\n",
    "    try:\n",
    "        content = soup.find('div', { 'class': 'article_body' }).get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        content = 'N/A'\n",
    "\n",
    "    try:\n",
    "        byline = soup.find('div', { 'class': 'byline'})\n",
    "        reporter = byline.find('a').get_text(strip=True).split('\\n')[0]\n",
    "    except AttributeError:\n",
    "        reporter = 'N/A'\n",
    "\n",
    "    return headline, time, content, reporter\n",
    "\n",
    "# Ïä§ÌÅ¨Îû© Ïù¥ÌõÑ Ï§ëÎ≥µ Îç∞Ïù¥ÌÑ∞ Ï†úÍ±∞ ÌõÑÏ≤òÎ¶¨ Ìï®Ïàò\n",
    "def remove_duplicates_by_time(df):\n",
    "    # Remove rows where the 'time' field is the same, keeping the first occurrence\n",
    "    df = df.drop_duplicates(subset='time', keep='first').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://www.joongang.co.kr/politics\"\n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "cards = soup.find_all('li', class_='card')\n",
    "for card in cards:\n",
    "    article_link = card.find('a', href=True)['href']\n",
    "    print(f\"Scraping article: {article_link}\")\n",
    "\n",
    "    # 1Ï∞® Í≤∞Í≥º Í≤ÄÏ¶ù\n",
    "    result = scrape_article(article_link)\n",
    "\n",
    "    if result is None:\n",
    "        continue\n",
    "\n",
    "    headline, time, content, reporter = result\n",
    "\n",
    "    # 2Ï∞® Í≤∞Í≥º Í≤ÄÏ¶ù\n",
    "    if 'N/A' in [headline, time, content, reporter]:\n",
    "        print(f\"Skipping article because {[headline, time, content, reporter]}: missing required fields.\")\n",
    "        continue\n",
    "\n",
    "    joongang_news_df.loc[idx] = [headline, time, content, reporter]\n",
    "    idx += 1\n",
    "\n",
    "# ÏµúÏã†Ïàú Ï†ïÎ†¨\n",
    "# 1. timeÏùò Îç∞Ïù¥ÌÑ∞Î•º datetime ÌòïÏãùÏúºÎ°ú Î≥ÄÍ≤Ω\n",
    "joongang_news_df['time'] = pd.to_datetime(joongang_news_df['time'])\n",
    "\n",
    "# 2. ÏãúÍ∞Ñ Í∏∞Ï§Ä ÎÇ¥Î¶ºÏ∞®Ïàú Ï†ïÎ†¨\n",
    "joongang_news_df = joongang_news_df.sort_values(by='time', ascending=False)\n",
    "\n",
    "# 3. ÏãúÍ∞Ñ Í∏∞Ï§ÄÏúºÎ°ú Ï§ëÎ≥µ Ï†úÍ±∞\n",
    "joongang_news_df = remove_duplicates_by_time(joongang_news_df)\n",
    "\n",
    "# 4. Îã§Ïãú time ÌòïÏãù Î≥ÄÍ≤Ω\n",
    "joongang_news_df['time'] = joongang_news_df['time'].dt.strftime('%Y-%m-%dT%H:%M:%S%z')\n",
    "\n",
    "joongang_news_df.to_json('./joongang-articles/joongang_articles.json', orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéà ÌÖåÏä§Ìä∏\n",
    "\n",
    "### 1Í±¥Ïî© Ï°∞ÌöåÌïòÏó¨ Îã®Ïùº Í∏∞ÏÇ¨Î≥Ñ ÌååÏùº ÏÉùÏÑ±\n",
    "---\n",
    "\n",
    "1. ÌååÏùº type: json\n",
    "\n",
    "2. ÌååÏùºÎ™Ö ÌòïÏãù: uuid\n",
    "\n",
    "3. ÌïÑÎìú\n",
    "\n",
    "    - headline\n",
    "    \n",
    "    - time -> '%Y-%m-%dT%H:%M:%S%z'\n",
    "    \n",
    "    - content\n",
    "\n",
    "    - reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping article: https://www.joongang.co.kr/article/25278499\n",
      "Skipping article https://www.joongang.co.kr/article/25278499: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278695\n",
      "Skipping article https://www.joongang.co.kr/article/25278695: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278704\n",
      "Skipping article https://www.joongang.co.kr/article/25278704: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278507\n",
      "Skipping article https://www.joongang.co.kr/article/25278507: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278788\n",
      "Skipping article https://www.joongang.co.kr/article/25278788: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278704\n",
      "Skipping article https://www.joongang.co.kr/article/25278704: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278705\n",
      "Article saved to ./joongang-articles\\7256080b-dda7-46f8-8e5f-ffec98a43a81.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278775\n",
      "Article saved to ./joongang-articles\\d64abcaf-6684-4cff-be8a-dbf50db1aec0.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278773\n",
      "Article saved to ./joongang-articles\\71094264-fa7c-4303-833f-a3a4ded3474b.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278590\n",
      "Article saved to ./joongang-articles\\4ecc2211-7755-4bf2-9097-065df9ac1a85.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278775\n",
      "Article saved to ./joongang-articles\\612d3b7a-b16e-454a-9236-54f93b33bb97.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278773\n",
      "Article saved to ./joongang-articles\\6eaede11-dd3a-45f9-9901-4df00a206862.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278717\n",
      "Article saved to ./joongang-articles\\2598455c-b96e-4644-84d6-49c9716007fc.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278705\n",
      "Article saved to ./joongang-articles\\32ef5209-58ef-49cc-9d1c-3f3a8134f538.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278708\n",
      "Article saved to ./joongang-articles\\1249682b-57e1-4b7b-a1e5-ec2529215d7d.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278704\n",
      "Skipping article https://www.joongang.co.kr/article/25278704: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278702\n",
      "Article saved to ./joongang-articles\\f180a555-3629-414b-a2e7-9284f2e900a2.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278701\n",
      "Article saved to ./joongang-articles\\9bd1a60c-9a12-4acd-af74-1486cd8d3172.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278677\n",
      "Article saved to ./joongang-articles\\6f140788-02f6-4017-9736-50763a7cc6ff.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278673\n",
      "Article saved to ./joongang-articles\\eb0e1e25-ae90-42b5-afa5-3538abdbd2cb.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278671\n",
      "Article saved to ./joongang-articles\\2bfade76-31cf-4176-9328-9cee549895d8.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278638\n",
      "Article saved to ./joongang-articles\\3fa3a644-c007-4310-885e-9cafe5cb90c3.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278630\n",
      "Article saved to ./joongang-articles\\35d1c0fa-1a83-4560-9d83-d8eb70fee800.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278620\n",
      "Article saved to ./joongang-articles\\1482f06d-0cbe-414d-93e2-ed5f8b520d29.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278610\n",
      "Article saved to ./joongang-articles\\0cc3cbfa-d1f4-4cf5-8588-5dc380e18c3b.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278607\n",
      "Article saved to ./joongang-articles\\300dd1a1-2c25-4044-bf5e-ba9d41678daa.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278598\n",
      "Article saved to ./joongang-articles\\f64f4d57-4064-44bc-932a-1527893f2b79.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278590\n",
      "Article saved to ./joongang-articles\\c238c5f6-cab2-4193-8df1-fbd27f2f458a.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278576\n",
      "Skipping article https://www.joongang.co.kr/article/25278576: not a Politics article.\n",
      "Scraping article: https://www.joongang.co.kr/article/25278562\n",
      "Article saved to ./joongang-articles\\0acdcaa9-2b21-4cb2-b0e0-de8e8a2558f8.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278556\n",
      "Article saved to ./joongang-articles\\000f2e2f-0bd3-4637-981c-c864da55925a.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278536\n",
      "Article saved to ./joongang-articles\\af92aa8c-b673-4ead-ac10-aa3a6ac5b52b.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278532\n",
      "Article saved to ./joongang-articles\\8c276467-1926-48ed-89ea-423d57b3135d.json\n",
      "Scraping article: https://www.joongang.co.kr/article/25278529\n",
      "Article saved to ./joongang-articles\\aa87a71c-6a89-409e-a851-503ba03eb73c.json\n",
      "Waiting for new articles...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "# ÏòàÏô∏ Ï≤òÎ¶¨\n",
    "output_dir = './joongang-articles'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "header = {'User-Agent': ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "                         '(KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'),}\n",
    "\n",
    "# Ïä§ÌÅ¨Îû© Ìï®Ïàò\n",
    "def scrape_article(article_url):\n",
    "    response = requests.get(article_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        category = soup.find('a', {'class': 'title'}).get_text(strip=True)\n",
    "        if category != 'Ï†ïÏπò':  # Ï†ïÏπòÍ∞Ä ÏïÑÎãàÎ©¥ Ìå®Ïä§\n",
    "            print(f\"Skipping article {article_url}: not a Politics article.\")\n",
    "            return None\n",
    "    except AttributeError:\n",
    "        print(f\"Skipping article {article_url}: category not found.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        headline = soup.find('h1', {'class': 'headline'}).get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        headline = 'N/A'\n",
    "\n",
    "    try:\n",
    "        date = soup.find('p', {'class': 'date'})\n",
    "        time = date.find('time').get('datetime')\n",
    "    except AttributeError:\n",
    "        time = 'N/A'\n",
    "\n",
    "    try:\n",
    "        content = soup.find('div', {'class': 'article_body'}).get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        content = 'N/A'\n",
    "\n",
    "    try:\n",
    "        byline = soup.find('div', {'class': 'byline'})\n",
    "        reporter = byline.find('a').get_text(strip=True).split('\\n')[0]\n",
    "    except AttributeError:\n",
    "        reporter = 'N/A'\n",
    "\n",
    "    return {'headline': headline, 'time': time, 'content': content, 'reporter': reporter}\n",
    "\n",
    "# ÌååÏùº ÏÉùÏÑ±\n",
    "def save_article_as_json(article_data):\n",
    "    file_name = str(uuid.uuid4()) + '.json'\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "    \n",
    "    # Îã®Ïùº dataframe ÏÉùÏÑ±\n",
    "    single_article_df = pd.DataFrame([article_data])\n",
    "    \n",
    "    # jsonÏúºÎ°ú Î≥ÄÌôò\n",
    "    single_article_df.to_json(file_path, orient='records', lines=True, force_ascii=False)\n",
    "    print(f\"Article saved to {file_path}\")\n",
    "\n",
    "# ÏÉàÎ°úÏö¥ Í∏∞ÏÇ¨ Ïä§ÌÅ¨Îû©\n",
    "def check_for_new_articles():\n",
    "    base_url = \"https://www.joongang.co.kr/politics\"\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    cards = soup.find_all('li', class_='card')\n",
    "    for card in cards:\n",
    "        article_link = card.find('a', href=True)['href']\n",
    "        print(f\"Scraping article: {article_link}\")\n",
    "\n",
    "        # Scrape the article\n",
    "        result = scrape_article(article_link)\n",
    "\n",
    "        if result is None:\n",
    "            continue\n",
    "\n",
    "        # Save each article individually\n",
    "        save_article_as_json(result)\n",
    "\n",
    "# Ïã§Ìñâ\n",
    "while True:\n",
    "    check_for_new_articles()\n",
    "    print(\"Waiting for new articles...\")\n",
    "    time.sleep(600)  # 10Î∂ÑÏóê Ìïú Î≤à"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéà ÌÖåÏä§Ìä∏\n",
    "\n",
    "### S3 ÏóÖÎ°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# S3 setup (ensure AWS credentials are configured via AWS CLI or environment variables)\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'your-s3-bucket-name'\n",
    "\n",
    "# Scrape article function\n",
    "def scrape_article(article_url):\n",
    "    response = requests.get(article_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        category = soup.find('a', {'class': 'title'}).get_text(strip=True)\n",
    "        if category != 'Ï†ïÏπò':  # Skip non-Politics articles\n",
    "            print(f\"Skipping article {article_url}: not a Politics article.\")\n",
    "            return None\n",
    "    except AttributeError:\n",
    "        print(f\"Skipping article {article_url}: category not found.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        headline = soup.find('h1', {'class': 'headline'}).get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        headline = 'N/A'\n",
    "\n",
    "    try:\n",
    "        date = soup.find('p', {'class': 'date'})\n",
    "        time = date.find('time').get('datetime')\n",
    "    except AttributeError:\n",
    "        time = 'N/A'\n",
    "\n",
    "    try:\n",
    "        content = soup.find('div', {'class': 'article_body'}).get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        content = 'N/A'\n",
    "\n",
    "    try:\n",
    "        byline = soup.find('div', {'class': 'byline'})\n",
    "        reporter = byline.find('a').get_text(strip=True).split('\\n')[0]\n",
    "    except AttributeError:\n",
    "        reporter = 'N/A'\n",
    "\n",
    "    return {'headline': headline, 'time': time, 'content': content, 'reporter': reporter}\n",
    "\n",
    "# Save article as JSON and upload to S3\n",
    "def save_article_to_s3(article_data):\n",
    "    # Generate UUID for the file name\n",
    "    file_name = str(uuid.uuid4()) + '.json'\n",
    "    json_data = pd.DataFrame([article_data])\n",
    "\n",
    "    # Save locally before uploading to S3\n",
    "    local_file_path = '/tmp/' + file_name  # Using /tmp to avoid filling local storage\n",
    "    json_data.to_json(local_file_path, orient='records', lines=True, force_ascii=False)\n",
    "\n",
    "    # Upload the JSON file to S3\n",
    "    try:\n",
    "        s3.upload_file(local_file_path, bucket_name, f'joongang-articles/{file_name}')\n",
    "        print(f\"Uploaded {file_name} to S3 bucket {bucket_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading {file_name}: {e}\")\n",
    "\n",
    "    # Optionally, remove the local file after upload\n",
    "    os.remove(local_file_path)\n",
    "\n",
    "# Check for new articles\n",
    "def check_for_new_articles():\n",
    "    base_url = \"https://www.joongang.co.kr/politics\"\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    cards = soup.find_all('li', class_='card')\n",
    "    for card in cards:\n",
    "        article_link = card.find('a', href=True)['href']\n",
    "        print(f\"Scraping article: {article_link}\")\n",
    "\n",
    "        # Scrape the article\n",
    "        result = scrape_article(article_link)\n",
    "\n",
    "        if result is None:\n",
    "            continue\n",
    "\n",
    "        # Save and upload article to S3\n",
    "        save_article_to_s3(result)\n",
    "\n",
    "# Continuously monitor the site for new articles\n",
    "while True:\n",
    "    check_for_new_articles()\n",
    "    print(\"Waiting for new articles...\")\n",
    "    time.sleep(600)  # Wait for 10 minutes before checking again\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
